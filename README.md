#                          Text Mining for Economic Crisis

***
***

## Description

The folder contains 3 type of scripts:
 - ** 1. Clean_urls_XXX.r**: given the dataframe of urls from the scrapping of the web, clean the metadata to obtain only relevant documents (separate sup and corr; find the name of the country, create additional variables on the type of documents and content given IMF keywords,...) and provide the subsample of urls interesting to download.
      - **1.1. Clean_urls_IMFSBA_Reviews.r**: 
      - **1.2. Clean_urls_IMFECF_Requests.r**:
      - **1.3. Clean_urls_IMFECF_ESAF_Requests.r**:
 - **2. Download_pdf_from_urls.r**: given a dataframe containing the urls of the files to download, the script download the pdfs and store them in the folder of your choice.
 - **3. Text_mining_crisis.r**: from the files downloaded by the previous script, this script performs the text analysis on the corpus of you choice and create several folders containing the folders:
    - 1.corpus: provides the corpus of the analisis in RData format 
    - 2.data: provides the datasets of tf_idf, and number of occurence of each category in each document as well as the cosinus similarity matrix of all categories
    -3.graphs:provides the plots of the cosinus similarity matrix for each category, the radar chart of the corpus, the average tf and tf-idf for the corpus
    - Output.RData is a list containing all the inputs and output.
 
The numbered folders are generated by the code and must be deleted before running the script **3. Text_mining_crisis,r** if not the script will not recompute the td-idf but will use the existring one.
## Author

- Manuel Betin

## Language

- R 

## Dependencies

### Libraries

- **SetUpProject** (own package not on cran, contact: manubetin@gmail.com for details)
- **TextMiningCrisis** (own package not on cran, contact: manubetin@gmail.com for details)

- pdftools
- xml2
- rvest
- tidytext
- tidyr
- stringr
- stringi
- tidytext
- dplyr
- tidyr
- plotly
- ggplot2
- rio
- tictoc
- lubridate